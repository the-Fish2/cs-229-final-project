{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120865eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 20:44:27.580160: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-08 20:44:27.916349: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-08 20:44:27.916435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-08 20:44:27.964019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-08 20:44:28.059508: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-08 20:44:29.468893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-12-08 20:44:31.999741: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /tensorflow/core/bfc_allocator_delay. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2025-12-08 20:44:32.002795: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /xla/service/gpu/compiled_programs_count. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2025-12-08 20:44:32.016429: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /jax/pjrt/pjrt_executable_executions. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2025-12-08 20:44:32.016519: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /jax/pjrt/pjrt_executable_execution_time_usecs. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2025-12-08 20:44:33.657696: I itex/core/wrapper/itex_gpu_wrapper.cc:38] Intel Extension for Tensorflow* GPU backend is loaded.\n",
      "2025-12-08 20:44:33.659408: I external/local_xla/xla/pjrt/pjrt_api.cc:67] PJRT_Api is set for device type xpu\n",
      "2025-12-08 20:44:33.659440: I external/local_xla/xla/pjrt/pjrt_api.cc:72] PJRT plugin for XPU has PJRT API version 0.33. The framework PJRT API version is 0.34.\n",
      "2025-12-08 20:44:33.791126: I external/intel_xla/xla/stream_executor/sycl/sycl_gpu_runtime.cc:134] Selected platform: Intel(R) oneAPI Unified Runtime over Level-Zero V2\n",
      "2025-12-08 20:44:33.791483: I external/intel_xla/xla/stream_executor/sycl/sycl_gpu_runtime.cc:159] number of sub-devices is zero, expose root device.\n",
      "2025-12-08 20:44:33.795192: I external/xla/xla/service/service.cc:168] XLA service 0x349cd7d0 initialized for platform SYCL (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-08 20:44:33.795227: I external/xla/xla/service/service.cc:176]   StreamExecutor device (0): Intel(R) Arc(TM) Graphics, <undefined>\n",
      "2025-12-08 20:44:33.796763: I itex/core/devices/gpu/itex_gpu_runtime.cc:130] Selected platform: Intel(R) oneAPI Unified Runtime over Level-Zero V2\n",
      "2025-12-08 20:44:33.797062: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n",
      "2025-12-08 20:44:33.800056: I external/intel_xla/xla/pjrt/se_xpu_pjrt_client.cc:97] Using BFC allocator.\n",
      "2025-12-08 20:44:33.800184: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 13379132620 bytes on device 0 for BFCAllocator.\n",
      "2025-12-08 20:44:33.802439: I external/local_xla/xla/pjrt/pjrt_c_api_client.cc:119] PjRtCApiClient created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:XPU:0', device_type='XPU')]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from utils import function_utils\n",
    "print(tf.config.list_physical_devices('XPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca13cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lethan3/miniconda3/envs/tensorflowintel/lib/python3.11/site-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/lethan3/miniconda3/envs/tensorflowintel/lib/python3.11/site-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATASET\n",
    "\n",
    "# X = np.loadtxt('X_comp_1_3.npy', delimiter=',')\n",
    "X = function_utils.load_sympy_to_np_array('../../data/SE_comp_1_3.pkl')\n",
    "y = np.loadtxt('../../data/y_comp_1_3.npy', delimiter=',')\n",
    "\n",
    "# Preprocess the input\n",
    "for i in range(X.shape[0]):\n",
    "    if np.std(X[i]) == 0:\n",
    "        X[i] = 0\n",
    "        continue\n",
    "    X[i] = (X[i] - np.mean(X[i])) / np.std(X[i])\n",
    "# X = np.tanh(X)\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "perm = np.random.permutation(n_samples)  # random permutation of indices\n",
    "\n",
    "X_shuffled = X[perm]\n",
    "y_shuffled = y[perm]\n",
    "\n",
    "train_frac = 0.8\n",
    "n_train = int(train_frac * n_samples)\n",
    "\n",
    "X_train = X_shuffled[:n_train]\n",
    "y_train = y_shuffled[:n_train]\n",
    "X_val = X_shuffled[n_train:]\n",
    "y_val = y_shuffled[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81fad722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 50000, Valid size: 50000\n",
      "Sampled 5000 rows (~1/10)\n",
      "Train size: (4000, 5000), Val size: (1000, 5000)\n",
      "Arrays saved: X_train.npy, y_train.npy, X_val.npy, y_val.npy\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import function_utils  # assuming load_sympy_to_np_array is here\n",
    "\n",
    "# -----------------------\n",
    "# LOAD DATA\n",
    "# -----------------------\n",
    "# X = function_utils.load_sympy_to_np_array('SE_comp_1_3.pkl')\n",
    "# y = np.loadtxt('y_comp_1_3.npy', delimiter=',')\n",
    "\n",
    "# -----------------------\n",
    "# FILTER OUT NaNs / INFs\n",
    "# -----------------------\n",
    "valid_mask = ~np.isnan(X).any(axis=1) & ~np.isinf(X).any(axis=1)\n",
    "X_valid = X[valid_mask]\n",
    "y_valid = y[valid_mask]\n",
    "\n",
    "print(f\"Original size: {X.shape[0]}, Valid size: {X_valid.shape[0]}\")\n",
    "\n",
    "# -----------------------\n",
    "# RANDOM SAMPLE (1/10 of total)\n",
    "# -----------------------\n",
    "n_total = X_valid.shape[0]\n",
    "n_sample = max(1, n_total // 10)\n",
    "\n",
    "perm = np.random.permutation(n_total)\n",
    "selected_indices = perm[:n_sample]\n",
    "\n",
    "X_sample = X_valid[selected_indices]\n",
    "y_sample = y_valid[selected_indices]\n",
    "\n",
    "print(f\"Sampled {n_sample} rows (~1/10)\")\n",
    "\n",
    "# -----------------------\n",
    "# TRAIN / VALIDATION SPLIT\n",
    "# -----------------------\n",
    "train_frac = 0.8\n",
    "n_train = int(train_frac * n_sample)\n",
    "\n",
    "perm_sample = np.random.permutation(n_sample)\n",
    "X_sample = X_sample[perm_sample]\n",
    "y_sample = y_sample[perm_sample]\n",
    "\n",
    "X_train = X_sample[:n_train]\n",
    "y_train = y_sample[:n_train]\n",
    "X_val = X_sample[n_train:]\n",
    "y_val = y_sample[n_train:]\n",
    "\n",
    "print(f\"Train size: {X_train.shape}, Val size: {X_val.shape}\")\n",
    "\n",
    "# -----------------------\n",
    "# SAVE TO FILES\n",
    "# -----------------------\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('X_val.npy', X_val)\n",
    "np.save('y_val.npy', y_val)\n",
    "\n",
    "print(\"Arrays saved: X_train.npy, y_train.npy, X_val.npy, y_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc92f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains NaNs? False\n",
      "Contains Infs? False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assume X_train is your NumPy array of shape (n_samples, 5000)\n",
    "\n",
    "# Check for NaNs\n",
    "nan_mask = np.isnan(X_train)\n",
    "has_nans = np.any(nan_mask)\n",
    "\n",
    "# Check for Infs\n",
    "inf_mask = np.isinf(X_train)\n",
    "has_infs = np.any(inf_mask)\n",
    "\n",
    "print(f\"Contains NaNs? {has_nans}\")\n",
    "print(f\"Contains Infs? {has_infs}\")\n",
    "\n",
    "if has_nans:\n",
    "    nan_indices = np.argwhere(nan_mask)\n",
    "    print(\"Indices of NaNs (first 10):\", nan_indices[:10])\n",
    "\n",
    "if has_infs:\n",
    "    inf_indices = np.argwhere(inf_mask)\n",
    "    print(\"Indices of Infs (first 10):\", inf_indices[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84e17149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tfl = tf.keras.layers\n",
    "SAMPLES = 5000\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tfl.Input(shape=(SAMPLES, 1)),\n",
    "\n",
    "    tfl.SeparableConv1D(32, 7, padding=\"same\", dilation_rate=1),\n",
    "    tfl.LeakyReLU(alpha=0.1),\n",
    "    tfl.Dropout(0.1),\n",
    "\n",
    "    tfl.SeparableConv1D(32, 7, padding=\"same\", dilation_rate=2),\n",
    "    tfl.LeakyReLU(alpha=0.1),\n",
    "    tfl.Dropout(0.1),\n",
    "\n",
    "    tfl.SeparableConv1D(32, 7, padding=\"same\", dilation_rate=4),\n",
    "    tfl.LeakyReLU(alpha=0.1),\n",
    "    tfl.Dropout(0.1),\n",
    "\n",
    "    # Reduce max dilation to avoid exploding gradients\n",
    "    tfl.SeparableConv1D(32, 7, padding=\"same\", dilation_rate=8),\n",
    "    tfl.LeakyReLU(alpha=0.1),\n",
    "    tfl.Dropout(0.1),\n",
    "\n",
    "    tfl.Conv1D(16, 1, padding=\"same\"),\n",
    "    tfl.LeakyReLU(alpha=0.1),\n",
    "\n",
    "    tfl.GlobalAveragePooling1D(),\n",
    "    tfl.Dense(5, activation='relu')\n",
    "])\n",
    "\n",
    "# Optimizer with gradient clipping\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24540a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " separable_conv1d_20 (Separ  (None, 5000, 32)          71        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ableConv1D)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 5000, 32)          0         \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 5000, 32)          0         \n",
      "                                                                 \n",
      " separable_conv1d_21 (Separ  (None, 5000, 32)          1280      \n",
      " ableConv1D)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 5000, 32)          0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 5000, 32)          0         \n",
      "                                                                 \n",
      " separable_conv1d_22 (Separ  (None, 5000, 32)          1280      \n",
      " ableConv1D)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_27 (LeakyReLU)  (None, 5000, 32)          0         \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 5000, 32)          0         \n",
      "                                                                 \n",
      " separable_conv1d_23 (Separ  (None, 5000, 32)          1280      \n",
      " ableConv1D)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_28 (LeakyReLU)  (None, 5000, 32)          0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 5000, 32)          0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 5000, 16)          528       \n",
      "                                                                 \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 5000, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_5  (None, 16)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4524 (17.67 KB)\n",
      "Trainable params: 4524 (17.67 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8649b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_accuracy(y_true, y_pred):\n",
    "    y_pred_rounded = tf.round(y_pred)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred_rounded), tf.float32))\n",
    "\n",
    "def coral_eval(y_pred):\n",
    "    y_pred_evaled = np.sum(y_pred, axis=-1)\n",
    "    return y_pred_evaled\n",
    "\n",
    "def coral_accuracy(y_true, y_pred):\n",
    "    return rounded_accuracy(y_true, coral_eval(y_pred))\n",
    "\n",
    "def coral_targets(y, num_classes):\n",
    "    # y shape: (batch,)\n",
    "    y = tf.cast(y, tf.int32)\n",
    "    # generate matrix (batch, K-1)\n",
    "    thresholds = tf.range(1, num_classes)\n",
    "    return tf.cast(y[:, None] >= thresholds[None, :], tf.float32)\n",
    "\n",
    "def coral_mae_loss(y_true, y_pred):\n",
    "    # y_pred = logits (batch, K-1)\n",
    "    # convert y_true to threshold targets\n",
    "    num_classes = y_pred.shape[-1] + 1\n",
    "    t = coral_targets(y_true, num_classes)\n",
    "    \n",
    "    # standard BCE_loss, but applied across K-1 thresholds\n",
    "    # loss = tf.keras.losses.binary_crossentropy(t, y_pred, from_logits=True)\n",
    "    loss = tf.reduce_mean(tf.pow((t - y_pred), 2))\n",
    "    \n",
    "    # average across thresholds\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=coral_mae_loss,\n",
    "              metrics=[rounded_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db345fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 20:59:22.534389: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onednn_verbose,v1,info,oneDNN v3.8.0 (commit 5dc2e69f319ab59520c9096436488c11ab86fd93)\n",
      "onednn_verbose,v1,info,cpu,runtime:DPC++,nthr:1\n",
      "onednn_verbose,v1,info,cpu,isa:Intel AVX2 with Intel DL Boost, float16 and bfloat16 support\n",
      "onednn_verbose,v1,info,gpu,runtime:DPC++\n",
      "onednn_verbose,v1,info,cpu,engine,sycl cpu device count:1 \n",
      "onednn_verbose,v1,info,cpu,engine,0,backend:OpenCL,name:Intel(R) Core(TM) Ultra 7 258V,driver_version:2025.20.10\n",
      "onednn_verbose,v1,info,gpu,engine,sycl gpu device count:1 \n",
      "onednn_verbose,v1,info,gpu,engine,0,backend:Level Zero,name:Intel(R) Arc(TM) Graphics,driver_version:1.6.34666,binary_kernels:enabled\n",
      "onednn_verbose,v1,info,graph,backend,0:dnnl_backend\n",
      "onednn_verbose,v1,info,experimental features are enabled\n",
      "onednn_verbose,v1,info,use batch_normalization stats one pass is enabled\n",
      "onednn_verbose,v1,info,GPU convolution v2 is disabled\n",
      "onednn_verbose,v1,info,experimental functionality for sparse domain is enabled\n",
      "onednn_verbose,v1,primitive,info,template:operation,engine,primitive,implementation,prop_kind,memory_descriptors,attributes,auxiliary,problem_desc,exec_time\n",
      "onednn_verbose,v1,graph,info,template:operation,engine,partition_id,partition_kind,op_names,data_formats,logical_tensors,fpmath_mode,implementation,backend,exec_time\n",
      "10/10 [==============================] - 11s 783ms/step - loss: 232674.0625 - rounded_accuracy: 0.2540 - val_loss: 194206.2500 - val_rounded_accuracy: 0.2492\n",
      "Epoch 2/250\n",
      "10/10 [==============================] - 7s 704ms/step - loss: 221032.6094 - rounded_accuracy: 0.2540 - val_loss: 182914.6250 - val_rounded_accuracy: 0.2492\n",
      "Epoch 3/250\n",
      "10/10 [==============================] - 7s 722ms/step - loss: 206474.0938 - rounded_accuracy: 0.2540 - val_loss: 168832.7188 - val_rounded_accuracy: 0.2492\n",
      "Epoch 4/250\n",
      "10/10 [==============================] - 5s 511ms/step - loss: 192004.4844 - rounded_accuracy: 0.2493 - val_loss: 162365.7969 - val_rounded_accuracy: 0.2297\n",
      "Epoch 5/250\n",
      "10/10 [==============================] - 5s 500ms/step - loss: 190172.2656 - rounded_accuracy: 0.2346 - val_loss: 161513.4375 - val_rounded_accuracy: 0.2280\n",
      "Epoch 6/250\n",
      "10/10 [==============================] - 5s 501ms/step - loss: 189055.3750 - rounded_accuracy: 0.2437 - val_loss: 161696.5938 - val_rounded_accuracy: 0.2492\n",
      "Epoch 7/250\n",
      "10/10 [==============================] - 5s 503ms/step - loss: 188959.7500 - rounded_accuracy: 0.2479 - val_loss: 161391.5000 - val_rounded_accuracy: 0.2263\n",
      "Epoch 8/250\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 188840.9375 - rounded_accuracy: 0.2297 - val_loss: 161363.8125 - val_rounded_accuracy: 0.2267\n",
      "Epoch 9/250\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 188821.9688 - rounded_accuracy: 0.2284 - val_loss: 161348.5938 - val_rounded_accuracy: 0.2253\n",
      "Epoch 10/250\n",
      "10/10 [==============================] - 6s 606ms/step - loss: 188812.1094 - rounded_accuracy: 0.2346 - val_loss: 161356.5938 - val_rounded_accuracy: 0.2093\n",
      "Epoch 11/250\n",
      "10/10 [==============================] - 6s 630ms/step - loss: 188796.2812 - rounded_accuracy: 0.2299 - val_loss: 161352.3281 - val_rounded_accuracy: 0.2265\n",
      "Epoch 12/250\n",
      "10/10 [==============================] - 5s 530ms/step - loss: 188820.7188 - rounded_accuracy: 0.2403 - val_loss: 161343.6875 - val_rounded_accuracy: 0.2177\n",
      "Epoch 13/250\n",
      "10/10 [==============================] - 8s 784ms/step - loss: 188773.2188 - rounded_accuracy: 0.2250 - val_loss: 161324.8750 - val_rounded_accuracy: 0.2243\n",
      "Epoch 14/250\n",
      "10/10 [==============================] - 5s 548ms/step - loss: 188778.8594 - rounded_accuracy: 0.2293 - val_loss: 161321.3594 - val_rounded_accuracy: 0.2263\n",
      "Epoch 15/250\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 188769.9688 - rounded_accuracy: 0.2347 - val_loss: 161318.2969 - val_rounded_accuracy: 0.2495\n",
      "Epoch 16/250\n",
      "10/10 [==============================] - 5s 541ms/step - loss: 188774.3906 - rounded_accuracy: 0.2539 - val_loss: 161320.6406 - val_rounded_accuracy: 0.2170\n",
      "Epoch 17/250\n",
      "10/10 [==============================] - 5s 527ms/step - loss: 188762.4688 - rounded_accuracy: 0.2277 - val_loss: 161329.3281 - val_rounded_accuracy: 0.2093\n",
      "Epoch 18/250\n",
      "10/10 [==============================] - 5s 520ms/step - loss: 188759.8594 - rounded_accuracy: 0.2423 - val_loss: 161306.6562 - val_rounded_accuracy: 0.2258\n",
      "Epoch 19/250\n",
      "10/10 [==============================] - 7s 732ms/step - loss: 188759.2031 - rounded_accuracy: 0.2436 - val_loss: 161296.8906 - val_rounded_accuracy: 0.2582\n",
      "Epoch 20/250\n",
      "10/10 [==============================] - 8s 768ms/step - loss: 188765.2344 - rounded_accuracy: 0.2405 - val_loss: 161324.2344 - val_rounded_accuracy: 0.2492\n",
      "Epoch 21/250\n",
      "10/10 [==============================] - 7s 724ms/step - loss: 188763.8750 - rounded_accuracy: 0.2535 - val_loss: 161329.4688 - val_rounded_accuracy: 0.2492\n",
      "Epoch 22/250\n",
      " 7/10 [====================>.........] - ETA: 1s - loss: 187673.7188 - rounded_accuracy: 0.2604"
     ]
    }
   ],
   "source": [
    "# Prepare inputs for Conv1D: add channel dim and cast to float32\n",
    "X_train_in = np.asarray(X_train, dtype=np.float32)[..., np.newaxis]  # (batch, 5000, 1)\n",
    "X_val_in   = np.asarray(X_val,   dtype=np.float32)[..., np.newaxis]  # (batch, 5000, 1)\n",
    "\n",
    "# Targets to float32 (Keras accepts (batch,) or (batch,1); use (batch,1))\n",
    "y_train_in = np.asarray(y_train, dtype=np.float32)\n",
    "y_val_in   = np.asarray(y_val,   dtype=np.float32)\n",
    "print(y_train_in.shape)\n",
    "# if y_train_in.ndim == 1:\n",
    "#     y_train_in = y_train_in[:, np.newaxis]\n",
    "# if y_val_in.ndim == 1:\n",
    "#     y_val_in = y_val_in[:, np.newaxis]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train_in, y_train_in,\n",
    "    epochs=250,\n",
    "    batch_size=400,\n",
    "    validation_data=(X_val_in, y_val_in),\n",
    ")\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3c6afa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_model_12_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_model_12_8/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"conv_model_12_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b57258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 32\n",
    "# print(np.min(X_val[ind]))\n",
    "plt.plot(function_utils.XS, X_val[ind])\n",
    "print(y_val[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dffcbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 2s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.14187192, 0.65942744, 0.111665  ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round predictions\n",
    "y_pred = tf.round(model.predict(X_train, batch_size=32))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_pred = y_pred.numpy().astype(int).flatten()\n",
    "y_true = y_train.astype(int).flatten()\n",
    "\n",
    "# Compute totals per class (0..3 assumed)\n",
    "n_classes = 4\n",
    "tot = np.bincount(y_true, minlength=n_classes)\n",
    "correct = np.bincount(y_true[y_pred == y_true], minlength=n_classes)\n",
    "\n",
    "# Class-wise accuracy\n",
    "acc = correct / tot\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a92f5aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24225"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train == 0) / y_train.shape[0]\n",
    "# model(X_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75b8cd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[969,   0,   0,   0],\n",
       "       [ 17, 144, 854,   0],\n",
       "       [103, 159, 668,  83],\n",
       "       [ 96, 121, 673, 113]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, n_classes=4, normalize=False):\n",
    "    # Compute confusion matrix\n",
    "    cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[t, p] += 1\n",
    "    \n",
    "    # Optional normalization (row-wise)\n",
    "    if normalize:\n",
    "        cm = cm.astype(float)\n",
    "        row_sums = cm.sum(axis=1, keepdims=True)\n",
    "        cm = np.divide(cm, row_sums, where=row_sums != 0)\n",
    "\n",
    "    # Heatmap\n",
    "    fig = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "            z=cm,\n",
    "            x=[f\"{i}\" for i in range(n_classes)],\n",
    "            y=[f\"{i}\" for i in range(n_classes)],\n",
    "            colorscale=\"Viridis\",\n",
    "            text=cm,\n",
    "            texttemplate=\"%{text}\",\n",
    "            showscale=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Complexity Estimation Confusion Matrix\",\n",
    "        xaxis_title=\"Predicted Complexity\",\n",
    "        yaxis_title=\"True Complexity\",\n",
    "        width=600,\n",
    "        height=500,\n",
    "    )\n",
    "    \n",
    "    fig.write_image(f\"confusion.png\", scale=3)\n",
    "\n",
    "    return cm\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming x_train and y_train are your training data\n",
    "history = model.fit(X_train, y_train, epochs=250, batch_size=40000, validation_data=(X_val, y_val))\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowintel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
