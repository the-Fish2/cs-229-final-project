{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd86f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# test_gd_fit_affine.py\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "from function_utils import gen_random_example, XS\n",
    "from gd_fit_affine import fit_best_function\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.config.list_physical_devices('XPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f24d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gd_fit_affine import fit_best_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d9f50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello?\n",
      "YS [-0.5458884  -0.54567865 -0.54546879 ...  4.47770298  4.48052739\n",
      "  4.48335326]\n",
      "Sampled function:  1.47958672958682*exp(0.130058854576177*x) - 0.948885576107974\n",
      "Complexity 0, 1 templates\n",
      "Complexity 1, 10 templates\n",
      "Fitting template: a1*log(a0*x + b0) + b1\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 1.04845113 1.04859067 1.04873016]\n",
      "YS returned,  [       nan        nan        nan ... 1.04845113 1.04859067 1.04873016]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 3.32404581 3.32464644 3.32524679]\n",
      "YS returned,  [       nan        nan        nan ... 3.32404581 3.32464644 3.32524679]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 4.14491465 4.14540105 4.14588725]\n",
      "YS returned,  [       nan        nan        nan ... 4.14491465 4.14540105 4.14588725]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 2.13828569 2.13873987 2.13919384]\n",
      "YS returned,  [       nan        nan        nan ... 2.13828569 2.13873987 2.13919384]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 3.81313494 3.8135722  3.8140093 ]\n",
      "YS returned,  [       nan        nan        nan ... 3.81313494 3.8135722  3.8140093 ]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 0.63889795 0.63913941 0.63938081]\n",
      "YS returned,  [       nan        nan        nan ... 0.63889795 0.63913941 0.63938081]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 2.01628773 2.01651801 2.01674818]\n",
      "YS returned,  [       nan        nan        nan ... 2.01628773 2.01651801 2.01674818]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 2.623695   2.62427626 2.62485728]\n",
      "YS returned,  [       nan        nan        nan ... 2.623695   2.62427626 2.62485728]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 1.64390388 1.64424168 1.64457935]\n",
      "YS returned,  [       nan        nan        nan ... 1.64390388 1.64424168 1.64457935]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 0.09386058 0.09452174 0.09518129]\n",
      "YS returned,  [       nan        nan        nan ... 0.09386058 0.09452174 0.09518129]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 2.03849203 2.03886859 2.03924502]\n",
      "YS returned,  [       nan        nan        nan ... 2.03849203 2.03886859 2.03924502]\n",
      "HELLO?? None\n",
      "hello?\n",
      "YS [       nan        nan        nan ... 1.73487226 1.73521753 1.73556265]\n",
      "YS returned,  [       nan        nan        nan ... 1.73487226 1.73521753 1.73556265]\n",
      "HELLO?? None\n",
      "Best overall loss: 1000000000000.0000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "gen_values() missing 1 required positional argument: 'XS'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSampled function: \u001b[39m\u001b[33m'\u001b[39m, f_expr)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Fit best function\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m best_expr, best_params, best_loss = \u001b[43mfit_best_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_sampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest expression:\u001b[39m\u001b[33m\"\u001b[39m, best_expr)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters:\u001b[39m\u001b[33m\"\u001b[39m, best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/gd_fit_affine.py:203\u001b[39m, in \u001b[36mfit_best_function\u001b[39m\u001b[34m(f_sampled)\u001b[39m\n\u001b[32m    201\u001b[39m plt.figure(figsize=(\u001b[32m6\u001b[39m,\u001b[32m4\u001b[39m))\n\u001b[32m    202\u001b[39m plt.plot(XS, f_sampled, label=\u001b[33m\"\u001b[39m\u001b[33mTarget f(x)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m plt.plot(XS, \u001b[43mgen_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_overall_expr\u001b[49m\u001b[43m)\u001b[49m, label=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest fit, loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_overall_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    204\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    205\u001b[39m plt.ylabel(\u001b[33m\"\u001b[39m\u001b[33mf(x)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: gen_values() missing 1 required positional argument: 'XS'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Generate a target function\n",
    "RNG = np.random.default_rng(120)\n",
    "f_expr = gen_random_example(RNG, complexity=1)\n",
    "f_sampled = np.array([f_expr.subs(sp.symbols('x'), xi) for xi in XS], dtype=np.float64)\n",
    "print('Sampled function: ', f_expr)\n",
    "\n",
    "# Fit best function\n",
    "best_expr, best_params, best_loss = fit_best_function(f_sampled)\n",
    "print(\"Best expression:\", best_expr)\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab0585e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gen_values() missing 1 required positional argument: 'XS'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generate a target function\u001b[39;00m\n\u001b[32m      2\u001b[39m RNG = np.random.default_rng(\u001b[32m123\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m f_expr = \u001b[43mgen_random_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRNG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplexity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m f_sampled = np.array([f_expr.subs(sp.symbols(\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m), xi) \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m XS], dtype=np.float64)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSampled function: \u001b[39m\u001b[33m'\u001b[39m, f_expr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/function_utils.py:87\u001b[39m, in \u001b[36mgen_random_example\u001b[39m\u001b[34m(rng, complexity)\u001b[39m\n\u001b[32m     84\u001b[39m ys = np.asarray(ys)\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# if output is complex, eliminate imaginary part only if it's tiny\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.iscomplexobj(ys):\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# If the imag part is nonzero, mark as invalid\u001b[39;00m\n\u001b[32m     89\u001b[39m     bad = np.abs(ys.imag) > \u001b[32m1e-12\u001b[39m\n\u001b[32m     90\u001b[39m     ys = ys.real\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/function_utils.py:70\u001b[39m, in \u001b[36mvalidate\u001b[39m\u001b[34m(expr)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgen_values\u001b[39m(expr: sp.Expr, XS: np.ndarray) -> np.ndarray:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Safely evaluate a SymPy expression over XS.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    - Lets numpy naturally produce NaNs for invalid cases.\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m    - Removes infs.\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[33;03m    - Treats complex results as invalid and returns np.nan.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[33;03m    Works with log, sqrt, powers, rational functions, etc.\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# SymPy -> numpy numeric function\u001b[39;00m\n\u001b[32m     78\u001b[39m     f = sp.lambdify(sp.symbols(\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m), expr, modules=[\u001b[33m'\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mTypeError\u001b[39m: gen_values() missing 1 required positional argument: 'XS'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate a target function\n",
    "RNG = np.random.default_rng(123)\n",
    "f_expr = gen_random_example(RNG, complexity=1)\n",
    "f_sampled = np.array([f_expr.subs(sp.symbols('x'), xi) for xi in XS], dtype=np.float64)\n",
    "print('Sampled function: ', f_expr)\n",
    "\n",
    "# Fit best function\n",
    "best_expr, best_params, best_loss = fit_best_function(f_sampled)\n",
    "print(\"Best expression:\", best_expr)\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409821db",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_rng = np.random.default_rng(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face89ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rngs = [np.random.default_rng(master_rng.integers(0, 32)) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d859376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled function:  -0.31590102771709*(-0.44151871545505*x - 0.423349109811582)/(0.465081338229672*x + 0.630041950729872) - 1.36309628972832\n",
      "Complexity 0, 1 templates\n",
      "Complexity 1, 10 templates\n",
      "Fitting template: a1*exp(a0*x + b0) + b1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSampled function: \u001b[39m\u001b[33m'\u001b[39m, f_expr)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Fit best function\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m best_expr, best_params, best_loss = \u001b[43mfit_best_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_sampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest expression:\u001b[39m\u001b[33m\"\u001b[39m, best_expr)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters:\u001b[39m\u001b[33m\"\u001b[39m, best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/gd_fit_affine.py:261\u001b[39m, in \u001b[36mfit_best_function\u001b[39m\u001b[34m(f_sampled)\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mComplexity \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(templates)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m templates\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m expr_template, m \u001b[38;5;129;01min\u001b[39;00m templates:\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m     expr_filled, params, loss = \u001b[43mfit_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_sampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m loss < best_overall_loss:\n\u001b[32m    263\u001b[39m         best_overall_loss = loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/gd_fit_affine.py:194\u001b[39m, in \u001b[36mfit_expr\u001b[39m\u001b[34m(expr_template, f_sampled)\u001b[39m\n\u001b[32m    191\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    192\u001b[39m     _, param_dict = res\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     loss, params = \u001b[43mrun_GD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTEPS_INITIAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m     candidates.append((loss, params))\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/gd_fit_affine.py:174\u001b[39m, in \u001b[36mrun_GD\u001b[39m\u001b[34m(param_dict, steps)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/.venv/lib/python3.13/site-packages/keras/src/optimizers/base_optimizer.py:462\u001b[39m, in \u001b[36mBaseOptimizer.apply_gradients\u001b[39m\u001b[34m(self, grads_and_vars)\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[32m    461\u001b[39m     grads, trainable_variables = \u001b[38;5;28mzip\u001b[39m(*grads_and_vars)\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[32m    464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterations\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/.venv/lib/python3.13/site-packages/keras/src/optimizers/base_optimizer.py:526\u001b[39m, in \u001b[36mBaseOptimizer.apply\u001b[39m\u001b[34m(self, grads, trainable_variables)\u001b[39m\n\u001b[32m    523\u001b[39m     grads = [g \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m g / scale \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[32m    525\u001b[39m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/.venv/lib/python3.13/site-packages/keras/src/optimizers/base_optimizer.py:592\u001b[39m, in \u001b[36mBaseOptimizer._backend_apply_gradients\u001b[39m\u001b[34m(self, grads, trainable_variables)\u001b[39m\n\u001b[32m    589\u001b[39m     \u001b[38;5;28mself\u001b[39m._apply_weight_decay(trainable_variables)\n\u001b[32m    591\u001b[39m     \u001b[38;5;66;03m# Run update step.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend_update_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlearning_rate\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_ema:\n\u001b[32m    597\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_model_variables_moving_average(\n\u001b[32m    598\u001b[39m         \u001b[38;5;28mself\u001b[39m._trainable_variables\n\u001b[32m    599\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/optimizer.py:119\u001b[39m, in \u001b[36mTFOptimizer._backend_update_step\u001b[39m\u001b[34m(self, grads, trainable_variables, learning_rate)\u001b[39m\n\u001b[32m    114\u001b[39m trainable_variables = [\n\u001b[32m    115\u001b[39m     v.value \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, backend.Variable) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m trainable_variables\n\u001b[32m    117\u001b[39m ]\n\u001b[32m    118\u001b[39m grads_and_vars = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m grads_and_vars = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_all_reduce_sum_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mself\u001b[39m._distributed_tf_update_step,\n\u001b[32m    122\u001b[39m     \u001b[38;5;28mself\u001b[39m._distribution_strategy,\n\u001b[32m    123\u001b[39m     grads_and_vars,\n\u001b[32m    124\u001b[39m     learning_rate,\n\u001b[32m    125\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/optimizer.py:159\u001b[39m, in \u001b[36mTFOptimizer._all_reduce_sum_gradients\u001b[39m\u001b[34m(self, grads_and_vars)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filtered_grads_and_vars:\n\u001b[32m    158\u001b[39m     grads = [pair[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m filtered_grads_and_vars]\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     reduced = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistribute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_replica_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mall_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistribute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mReduceOp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    163\u001b[39m     reduced = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/.venv/lib/python3.13/site-packages/tensorflow/python/distribute/distribute_lib.py:3641\u001b[39m, in \u001b[36mReplicaContextBase.all_reduce\u001b[39m\u001b[34m(self, reduce_op, value, options)\u001b[39m\n\u001b[32m   3639\u001b[39m     \u001b[38;5;66;03m# The gradient of an all-sum is itself an all-sum (all-mean, likewise).\u001b[39;00m\n\u001b[32m   3640\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ys, \u001b[38;5;28;01mlambda\u001b[39;00m *dy_s: \u001b[38;5;28mself\u001b[39m.all_reduce(reduce_op, dy_s)\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m nest.pack_sequence_as(value, \u001b[43mgrad_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflattened_value\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3643\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m has_indexed_slices:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/.venv/lib/python3.13/site-packages/tensorflow/python/ops/custom_gradient.py:339\u001b[39m, in \u001b[36mBind.__call__\u001b[39m\u001b[34m(self, *a, **k)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *a, **k):\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/.venv/lib/python3.13/site-packages/tensorflow/python/ops/custom_gradient.py:293\u001b[39m, in \u001b[36mcustom_gradient.<locals>.decorated\u001b[39m\u001b[34m(wrapped, args, kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decorated function with custom gradient.\"\"\"\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_mode_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    295\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _graph_mode_decorator(wrapped, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/.venv/lib/python3.13/site-packages/tensorflow/python/ops/custom_gradient.py:593\u001b[39m, in \u001b[36m_eager_mode_decorator\u001b[39m\u001b[34m(f, args, kwargs)\u001b[39m\n\u001b[32m    588\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    589\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcustom_gradient function expected to return \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    590\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgradients, but returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(flat_grads)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    591\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m flat_grads + variable_grads\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m \u001b[43mrecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord_operation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecorded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mactual_grad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    595\u001b[39m flat_result = composite_tensor_gradient.replace_flat_tensors_for_gradients(\n\u001b[32m    596\u001b[39m     nest.flatten(result), flat_result)\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nest.pack_sequence_as(result, flat_result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/gh_temp/cs-229-final-project/.venv/lib/python3.13/site-packages/tensorflow/python/eager/record.py:84\u001b[39m, in \u001b[36mrecord_operation\u001b[39m\u001b[34m(op_type, output_tensors, input_tensors, backward_function, forward_function)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrecord_operation\u001b[39m(op_type, output_tensors, input_tensors, backward_function,\n\u001b[32m     82\u001b[39m                      forward_function=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     83\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Records the operation on all tapes in the stack.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m   \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_TapeSetRecordOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m                                           \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackward_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m                                           \u001b[49m\u001b[43mforward_function\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "# Generate a target function\n",
    "    f_expr = gen_random_example(rngs[i], complexity=1)\n",
    "    f_sampled = np.array([f_expr.subs(sp.symbols('x'), xi) for xi in XS], dtype=np.float64)\n",
    "    print('Sampled function: ', f_expr)\n",
    "\n",
    "    # Fit best function\n",
    "    best_expr, best_params, best_loss = fit_best_function(f_sampled)\n",
    "    print(\"Best expression:\", best_expr)\n",
    "    print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db11f9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
